{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NIKHIL_SINGH_Session7.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/nikhilsingh291/visual_q_ans/blob/master/NIKHIL_SINGH_Session7.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "nGAM7AkNo5tq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LnKAVzfPo7Ra",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Deep Learning for Visual Question Answering\n",
        "\n",
        "\n",
        "![alt text](https://avisingh599.github.io/images/vqa/sample_results.jpg)\n",
        "\n",
        "This is about answering general english questions based on images by deep learning.\n",
        "\n",
        "I will be using LSTM+CNN approach to solve this problem and get a better accuracy."
      ]
    },
    {
      "metadata": {
        "id": "wwovdGnMziqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "faa3d84c-5cfc-422d-c9b8-d7db85cd02b0"
      },
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "%cd data\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gqPW7VjC00iq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        },
        "outputId": "f37a692a-80b6-48db-b414-be42c47f61ef"
      },
      "cell_type": "code",
      "source": [
        "# Downloads the training and validation sets from visualqa.org. \n",
        "\n",
        "!wget http://visualqa.org/data/mscoco/vqa/Questions_Train_mscoco.zip\n",
        "!wget http://visualqa.org/data/mscoco/vqa/Questions_Val_mscoco.zip\n",
        "!wget http://visualqa.org/data/mscoco/vqa/Annotations_Train_mscoco.zip\n",
        "!wget http://visualqa.org/data/mscoco/vqa/Annotations_Val_mscoco.zip\n",
        "\n",
        "!unzip \\*.zip"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-06-04 17:30:16--  http://visualqa.org/data/mscoco/vqa/Questions_Train_mscoco.zip\n",
            "Resolving visualqa.org (visualqa.org)... 128.173.88.40\n",
            "Connecting to visualqa.org (visualqa.org)|128.173.88.40|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21985607 (21M) [application/zip]\n",
            "Saving to: ‘Questions_Train_mscoco.zip’\n",
            "\n",
            "Questions_Train_msc 100%[===================>]  20.97M  23.5MB/s    in 0.9s    \n",
            "\n",
            "2018-06-04 17:30:17 (23.5 MB/s) - ‘Questions_Train_mscoco.zip’ saved [21985607/21985607]\n",
            "\n",
            "--2018-06-04 17:30:18--  http://visualqa.org/data/mscoco/vqa/Questions_Val_mscoco.zip\n",
            "Resolving visualqa.org (visualqa.org)... 128.173.88.40\n",
            "Connecting to visualqa.org (visualqa.org)|128.173.88.40|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10594497 (10M) [application/zip]\n",
            "Saving to: ‘Questions_Val_mscoco.zip’\n",
            "\n",
            "Questions_Val_mscoc 100%[===================>]  10.10M  14.4MB/s    in 0.7s    \n",
            "\n",
            "2018-06-04 17:30:18 (14.4 MB/s) - ‘Questions_Val_mscoco.zip’ saved [10594497/10594497]\n",
            "\n",
            "--2018-06-04 17:30:20--  http://visualqa.org/data/mscoco/vqa/Annotations_Train_mscoco.zip\n",
            "Resolving visualqa.org (visualqa.org)... 128.173.88.40\n",
            "Connecting to visualqa.org (visualqa.org)|128.173.88.40|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12167843 (12M) [application/zip]\n",
            "Saving to: ‘Annotations_Train_mscoco.zip’\n",
            "\n",
            "Annotations_Train_m 100%[===================>]  11.60M  16.0MB/s    in 0.7s    \n",
            "\n",
            "2018-06-04 17:30:20 (16.0 MB/s) - ‘Annotations_Train_mscoco.zip’ saved [12167843/12167843]\n",
            "\n",
            "--2018-06-04 17:30:22--  http://visualqa.org/data/mscoco/vqa/Annotations_Val_mscoco.zip\n",
            "Resolving visualqa.org (visualqa.org)... 128.173.88.40\n",
            "Connecting to visualqa.org (visualqa.org)|128.173.88.40|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6031604 (5.8M) [application/zip]\n",
            "Saving to: ‘Annotations_Val_mscoco.zip’\n",
            "\n",
            "Annotations_Val_msc 100%[===================>]   5.75M  8.70MB/s    in 0.7s    \n",
            "\n",
            "2018-06-04 17:30:22 (8.70 MB/s) - ‘Annotations_Val_mscoco.zip’ saved [6031604/6031604]\n",
            "\n",
            "Archive:  Questions_Train_mscoco.zip\n",
            "  inflating: OpenEnded_mscoco_train2014_questions.json  \n",
            "  inflating: MultipleChoice_mscoco_train2014_questions.json  \n",
            "\n",
            "Archive:  Annotations_Val_mscoco.zip\n",
            "  inflating: mscoco_val2014_annotations.json  \n",
            "\n",
            "Archive:  Annotations_Train_mscoco.zip\n",
            "  inflating: mscoco_train2014_annotations.json  \n",
            "\n",
            "Archive:  Questions_Val_mscoco.zip\n",
            "  inflating: OpenEnded_mscoco_val2014_questions.json  \n",
            "  inflating: MultipleChoice_mscoco_val2014_questions.json  \n",
            "\n",
            "4 archives were successfully processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N2pUh0pM0-xM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b3afab43-d192-47ce-d9de-db6d6ac1fff4"
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "%cd ..\n",
        "!ls\n",
        "!mkdir features"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Annotations_Train_mscoco.zip\r\n",
            "Annotations_Val_mscoco.zip\r\n",
            "features\r\n",
            "mscoco_train2014_annotations.json\r\n",
            "mscoco_val2014_annotations.json\r\n",
            "MultipleChoice_mscoco_train2014_questions.json\r\n",
            "MultipleChoice_mscoco_val2014_questions.json\r\n",
            "OpenEnded_mscoco_train2014_questions.json\r\n",
            "OpenEnded_mscoco_val2014_questions.json\r\n",
            "Questions_Train_mscoco.zip\r\n",
            "Questions_Val_mscoco.zip\r\n",
            "/content\n",
            "data  datalab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QBpjm3NK1e1I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "9e73858f-072c-4bbf-bb42-bffa51ffee8e"
      },
      "cell_type": "code",
      "source": [
        "%cd features\n",
        "!ls\n",
        "# Downloads and unzips the VGG features computed on the COCO dataset. \n",
        "\n",
        "!wget http://cs.stanford.edu/people/karpathy/deepimagesent/coco.zip\n",
        "!unzip coco.zip -d ."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/features\n",
            "--2018-06-04 17:34:34--  http://cs.stanford.edu/people/karpathy/deepimagesent/coco.zip\n",
            "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://cs.stanford.edu/people/karpathy/deepimagesent/coco.zip [following]\n",
            "--2018-06-04 17:34:34--  https://cs.stanford.edu/people/karpathy/deepimagesent/coco.zip\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 764830639 (729M) [application/zip]\n",
            "Saving to: ‘coco.zip’\n",
            "\n",
            "coco.zip             91%[=================>  ] 668.34M  14.4MB/s    eta 3s     "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "coco.zip            100%[===================>] 729.40M  15.7MB/s    in 30s     \n",
            "\n",
            "2018-06-04 17:35:04 (24.4 MB/s) - ‘coco.zip’ saved [764830639/764830639]\n",
            "\n",
            "Archive:  coco.zip\n",
            "  inflating: ./coco/dataset.json     \n",
            "  inflating: ./coco/readme.txt       \n",
            "  inflating: ./coco/vgg_feats.mat    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_iyENfrO2Yc_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "961f86a9-77fd-4e50-ab7d-9f2262aebd85"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "coco  coco.zip\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ctvGZMoR2eSe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "67737bdf-2393-455b-f536-10752c6fa715"
      },
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls\n",
        "!pip install spacy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/features\n",
            "coco  coco.zip\n",
            "Collecting spacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/31/e60f88751e48851b002f78a35221d12300783d5a43d4ef12fbf10cca96c3/spacy-2.0.11.tar.gz (17.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 17.6MB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.14.3)\n",
            "Collecting murmurhash<0.29,>=0.28 (from spacy)\n",
            "  Downloading https://files.pythonhosted.org/packages/5e/31/c8c1ecafa44db30579c8c457ac7a0f819e8b1dbc3e58308394fff5ff9ba7/murmurhash-0.28.0.tar.gz\n",
            "Collecting cymem<1.32,>=1.30 (from spacy)\n",
            "  Downloading https://files.pythonhosted.org/packages/f8/9e/273fbea507de99166c11cd0cb3fde1ac01b5bc724d9a407a2f927ede91a1/cymem-1.31.2.tar.gz\n",
            "Collecting preshed<2.0.0,>=1.0.0 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/ac/7c17b1fd54b60972785b646d37da2826311cca70842c011c4ff84fbe95e0/preshed-1.0.0.tar.gz (89kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 19.1MB/s \n",
            "\u001b[?25hCollecting thinc<6.11.0,>=6.10.1 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/fd/e9f36081e6f53699943381858848f3b4d759e0dd03c43b98807dde34c252/thinc-6.10.2.tar.gz (1.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.2MB 19.4MB/s \n",
            "\u001b[?25hCollecting plac<1.0.0,>=0.9.6 (from spacy)\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
            "Collecting pathlib (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/9b065a76b9af472437a0059f77e8f962fe350438b927cb80184c32f075eb/pathlib-1.0.1.tar.gz (49kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 16.8MB/s \n",
            "\u001b[?25hCollecting ujson>=1.35 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\n",
            "\u001b[K    100% |████████████████████████████████| 194kB 23.9MB/s \n",
            "\u001b[?25hCollecting dill<0.3,>=0.2 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/a0/19d4d31dee064fc553ae01263b5c55e7fb93daff03a69debbedee647c5a0/dill-0.2.7.1.tar.gz (64kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 19.2MB/s \n",
            "\u001b[?25hCollecting regex==2017.4.5 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
            "\u001b[K    100% |████████████████████████████████| 604kB 19.6MB/s \n",
            "\u001b[?25hCollecting wrapt (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/47/66897906448185fcb77fc3c2b1bc20ed0ecca81a0f2f88eda3fc5a34fc3d/wrapt-1.10.11.tar.gz\n",
            "Collecting tqdm<5.0.0,>=4.10.0 (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/24/6ab1df969db228aed36a648a8959d1027099ce45fad67532b9673d533318/tqdm-4.23.4-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hCollecting cytoolz<0.9,>=0.8 (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/e6/ccc124714dcc1bd511e64ddafb4d5d20ada2533b92e3173a4cf09e0d0831/cytoolz-0.8.2.tar.gz (386kB)\n",
            "\u001b[K    100% |████████████████████████████████| 389kB 23.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (1.11.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (1.1.0)\n",
            "Collecting msgpack-python (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/20/6eca772d1a5830336f84aca1d8198e5a3f4715cd1c7fc36d3cc7f7185091/msgpack-python-0.5.6.tar.gz (138kB)\n",
            "\u001b[K    100% |████████████████████████████████| 143kB 22.2MB/s \n",
            "\u001b[?25hCollecting msgpack-numpy==0.4.1 (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/43/393e30e2768b0357541ac95891f96b80ccc4d517e0dd2fa3042fc8926538/msgpack_numpy-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.9,>=0.8->thinc<6.11.0,>=6.10.1->spacy) (0.9.0)\n",
            "Building wheels for collected packages: spacy, murmurhash, cymem, preshed, thinc, pathlib, ujson, dill, regex, wrapt, cytoolz, msgpack-python\n",
            "  Running setup.py bdist_wheel for spacy ... \u001b[?25l-\b \b\\\b \b|\b \b/"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4oPkQDrYlrvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "960895f7-b3da-496a-8132-830158a5b2c4"
      },
      "cell_type": "code",
      "source": [
        "!python3 -m spacy download en"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 37.4MB 71.4MB/s \n",
            "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
            "  Running setup.py install for en-core-web-sm ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25hSuccessfully installed en-core-web-sm-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U8jtq2ofmHyK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from itertools import zip_longest\n",
        "from collections import defaultdict\n",
        "\n",
        "def selectFrequentAnswers(questions_train, answers_train, images_train, maxAnswers):\n",
        "\tanswer_fq= defaultdict(int)\n",
        "\t#build a dictionary of answers\n",
        "\tfor answer in answers_train:\n",
        "\t\tanswer_fq[answer] += 1\n",
        "\n",
        "\tsorted_fq = sorted(answer_fq.items(), key=operator.itemgetter(1), reverse=True)[0:maxAnswers]\n",
        "\ttop_answers, top_fq = zip(*sorted_fq)\n",
        "\tnew_answers_train=[]\n",
        "\tnew_questions_train=[]\n",
        "\tnew_images_train=[]\n",
        "\t#only those answer which appear int he top 1K are used for training\n",
        "\tfor answer,question,image in zip(answers_train, questions_train, images_train):\n",
        "\t\tif answer in top_answers:\n",
        "\t\t\tnew_answers_train.append(answer)\n",
        "\t\t\tnew_questions_train.append(question)\n",
        "\t\t\tnew_images_train.append(image)\n",
        "\n",
        "\treturn (new_questions_train,new_answers_train,new_images_train)\n",
        "\n",
        "def grouper(iterable, n, fillvalue=None):\n",
        "    args = [iter(iterable)] * n\n",
        "    return izip_longest(*args, fillvalue=fillvalue)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CH0B8UwF16Mw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "def get_questions_tensor_timeseries(questions, nlp, timesteps):\n",
        "\t'''\n",
        "\tReturns a time series of word vectors for tokens in the question\n",
        "\n",
        "\tInput:\n",
        "\tquestions: list of unicode objects\n",
        "\tnlp: an instance of the class English() from spacy.en\n",
        "\ttimesteps: the number of \n",
        "\n",
        "\tOutput:\n",
        "\tA numpy ndarray of shape: (nb_samples, timesteps, word_vec_dim)\n",
        "\t'''\n",
        "\tassert not isinstance(questions, basestring)\n",
        "\tnb_samples = len(questions)\n",
        "\tword_vec_dim = nlp(questions[0])[0].vector.shape[0]\n",
        "\tquestions_tensor = np.zeros((nb_samples, timesteps, word_vec_dim))\n",
        "\tfor i in xrange(len(questions)):\n",
        "\t\ttokens = nlp(questions[i])\n",
        "\t\tfor j in xrange(len(tokens)):\n",
        "\t\t\tif j<timesteps:\n",
        "\t\t\t\tquestions_tensor[i,j,:] = tokens[j].vector\n",
        "\n",
        "\treturn questions_tensor\n",
        "\n",
        "def get_questions_matrix_sum(questions, nlp):\n",
        "\t'''\n",
        "\tSums the word vectors of all the tokens in a question\n",
        "\t\n",
        "\tInput:\n",
        "\tquestions: list of unicode objects\n",
        "\tnlp: an instance of the class English() from spacy.en\n",
        "\n",
        "\tOutput:\n",
        "\tA numpy array of shape: (nb_samples, word_vec_dim)\t\n",
        "\t'''\n",
        "\tassert not isinstance(questions, basestring)\n",
        "\tnb_samples = len(questions)\n",
        "\tword_vec_dim = nlp(questions[0])[0].vector.shape[0]\n",
        "\tquestions_matrix = np.zeros((nb_samples, word_vec_dim))\n",
        "\tfor i in xrange(len(questions)):\n",
        "\t\ttokens = nlp(questions[i])\n",
        "\t\tfor j in xrange(len(tokens)):\n",
        "\t\t\tquestions_matrix[i,:] += tokens[j].vector\n",
        "\n",
        "\treturn questions_matrix\n",
        "\n",
        "def get_answers_matrix(answers, encoder):\n",
        "\t'''\n",
        "\tConverts string objects to class labels\n",
        "\n",
        "\tInput:\n",
        "\tanswers:\ta list of unicode objects\n",
        "\tencoder:\ta scikit-learn LabelEncoder object\n",
        "\n",
        "\tOutput:\n",
        "\tA numpy array of shape (nb_samples, nb_classes)\n",
        "\t'''\n",
        "\tassert not isinstance(answers, basestring)\n",
        "\ty = encoder.transform(answers) #string to numerical class\n",
        "\tnb_classes = encoder.classes_.shape[0]\n",
        "\tY = np_utils.to_categorical(y, nb_classes)\n",
        "\treturn Y\n",
        "\n",
        "def get_images_matrix(img_coco_ids, img_map, VGGfeatures):\n",
        "\t'''\n",
        "\tGets the 4096-dimensional CNN features for the given COCO\n",
        "\timages\n",
        "\t\n",
        "\tInput:\n",
        "\timg_coco_ids: \tA list of strings, each string corresponding to\n",
        "\t\t\t\t  \tthe MS COCO Id of the relevant image\n",
        "\timg_map: \t\tA dictionary that maps the COCO Ids to their indexes \n",
        "\t\t\t\t\tin the pre-computed VGG features matrix\n",
        "\tVGGfeatures: \tA numpy array of shape (nb_dimensions,nb_images)\n",
        "\n",
        "\tOuput:\n",
        "\tA numpy matrix of size (nb_samples, nb_dimensions)\n",
        "\t'''\n",
        "\tassert not isinstance(img_coco_ids, basestring)\n",
        "\tnb_samples = len(img_coco_ids)\n",
        "\tnb_dimensions = VGGfeatures.shape[0]\n",
        "\timage_matrix = np.zeros((nb_samples, nb_dimensions))\n",
        "\tfor j in xrange(len(img_coco_ids)):\n",
        "\t\timage_matrix[j,:] = VGGfeatures[:,img_map[img_coco_ids[j]]]\n",
        "\n",
        "\treturn image_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8AFvmv-Eho8m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "import sys\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation, Dropout, Reshape\n",
        "from keras.layers import Merge\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.utils import np_utils, generic_utils\n",
        "from keras.callbacks import ModelCheckpoint, RemoteMonitor\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "from sklearn import preprocessing\n",
        "\n",
        "#from spacy.en import English\n",
        "\n",
        "#from utils import grouper, selectFrequentAnswers\n",
        "#from features import get_images_matrix, get_answers_matrix, get_questions_tensor_timeseries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tX_x_QPh2A7V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e310bfe3-b935-4870-e83e-b46c407adb25"
      },
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RaqO0UPaqB86",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "f2e82965-c84d-410c-9513-1e18845446f0"
      },
      "cell_type": "code",
      "source": [
        "word_vec_dim= 300\n",
        "img_dim = 4096\n",
        "max_len = 30\n",
        "nb_classes = 1000\n",
        "\n",
        "questions_train = open('../data/preprocessed/questions_train2014.txt', 'r').read().decode('utf8').splitlines()\n",
        "questions_lengths_train = open('../data/preprocessed/questions_lengths_train2014.txt', 'r').read().decode('utf8').splitlines()\n",
        "answers_train = open('../data/preprocessed/answers_train2014_modal.txt', 'r').read().decode('utf8').splitlines()\n",
        "images_train = open('../data/preprocessed/images_train2014.txt', 'r').read().decode('utf8').splitlines()\n",
        "vgg_model_path = '../features/coco/vgg_feats.mat'"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-33180ee1d612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnb_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mquestions_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/preprocessed/questions_train2014.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mquestions_lengths_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/preprocessed/questions_lengths_train2014.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0manswers_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/preprocessed/answers_train2014_modal.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/preprocessed/questions_train2014.txt'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "KdqDLY75qF1i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}